TransferLearning
================
## 1. TransferLearning|전이학습 이란? 

TransferLearning|전이학습은 하나의 작업을 위해 훈련된 모델을 유사 작업 수행 모델의 시작점으로 활용하는 딥러닝 접근법입니다.일반적으로 신경망은 처음부터 새로 훈련하는 것보다 전이학습을 통해 업데이트하고 재훈련하는 편이 더 빠르고 간편합니다.

## 2. 장단점

전이학습은 다음과 같은 장점이 있습니다.

* 데이터가 적은 경우에도 높은 성능을 달성할 수 있습니다.
* 모델을 훈련하는 시간이 단축됩니다.
* 모델을 훈련하는 데 필요한 컴퓨팅 자원이 절감됩니다.

전이학습은 이미지 분류, 자연어 처리, 음성 인식 등 다양한 분야에서 사용되고 있습니다. 예를 들어, 이미지 분류에서 전이학습을 사용하면 사물의 종류를 분류하는 모델을 훈련할 때, 이미 훈련된 이미지 분류 모델을 시작점으로 활용할 수 있습니다. 이렇게 하면 데이터가 적은 경우에도 높은 성능을 달성할 수 있습니다.

전이학습은 딥러닝 모델을 훈련하는 데 매우 유용한 방법입니다. 데이터가 적은 경우에도 높은 성능을 달성할 수 있으며, 모델을 훈련하는 시간과 컴퓨팅 자원을 절감할 수 있습니다.

## 3. 활용

``` python
base_model = keras.models.Sequential([
  keras.layers.Flatten(input_shape=(28, 28)),
  keras.layers.Dense(3, activation='sigmoid'),
  keras.layers.Dense(10, activation='softmax')
])
```
위와 같이 구성된 모델이 있습니다. 이 모델에 mnist 데이터를 학습을 진행하고 평가값을 보면
```
loss : 1.1808340549468994 | accuracy : 0.6029000282287598
```
정확도가 낮게 나오는 것을 볼수 있습니다.
이미 이렇게 학습을 진행한 모델이 있다고 했을때에 정확도를 높이기 위해서 레이어를 수정해야할때에 구성하고 다시 훈련 시키는 비 효율적인 방법 말고 레이어를 추가하거나 삭제 하는 방법이 있습니다.
방법은 아래와 같습니다.

* Keras를 활용한 전이 학습 코드
```python
model = keras.Sequential() 
# 기존 모델의 전이받을 새로운 모델 생성
for index, layer in enumerate(base_model.layers):
    model.add(layer)
    #기존 모델의 레이어 추출 및 새로운 모델에 삽입
    if index == 1:
        #원하는 위치(index)에 레이어 추가
        model.add(Dropout(0.5)) #DropOut <= 과적합 문제 해결용

```

위 코드를 통해서 전이학습을 이해 할수도 있습니다.
전이 학습을 다시 간략히 설명하면 기존 모델의 레이어에 존재하는 weight를 새로운 모델에 입력 및 파라미터 조정 등을 통해 컴퓨팅 자원의 최소화 진행 가능 <br>
기존 학습된 모델의 가중치를 활용한 여러 파생 모델 생성 가능 또는 
학습 보완 가능(DropOut Layer 추가 등으로 과적합 방지)


___
출처 
```
https://kr.mathworks.com/discovery/transfer-learning.html
```

___
작성 마감일 : 2023.06.07
